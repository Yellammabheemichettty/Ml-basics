{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pandas_Assign_sol",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bHuLsXdreNX"
      },
      "source": [
        "# Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPvSwcd-ronH"
      },
      "source": [
        "**1.Convert the series ser into a dataframe with its index as another column on the dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xj_TYiSrTmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47053cbf-fdd9-4098-eaa1-9899d31d1ec6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Input\n",
        "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
        "myarr = np.arange(26)\n",
        "mydict = dict(zip(mylist, myarr))\n",
        "ser = pd.Series(mydict)\n",
        "# print(ser)\n",
        "df = ser.to_frame().reset_index() \n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  index  0\n",
            "0     a  0\n",
            "1     b  1\n",
            "2     c  2\n",
            "3     e  3\n",
            "4     d  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcLEqAYdr6RW"
      },
      "source": [
        "**2.Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Ab3ETAsIwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20591b20-41bf-421e-9d59-57c433ed2869"
      },
      "source": [
        "# Input\n",
        "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
        "# print(emails)\n",
        "import re\n",
        "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
        "mask = emails.str.match(pattern)\n",
        "# print(mask)\n",
        "emails[mask]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    rameses@egypt.com\n",
              "2            matt@t.co\n",
              "3    narendra@modi.com\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voyr7nfmsdSh"
      },
      "source": [
        "**3.Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa9PdCxdsbh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2728a4e8-79d8-4389-e71d-f1682a0bac2b"
      },
      "source": [
        "# Input\n",
        "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
        "print(ser.loc)\n",
        "autocorrelations = ser.autocorr(lag=1)\n",
        "print(autocorrelations) #autocorrelations[1:]\n",
        "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations))+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pandas.core.indexing._LocIndexer object at 0x7f748f88ab38>\n",
            "-0.04546261430145601\n",
            "Lag having highest correlation:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppp7ueBNs-wd"
      },
      "source": [
        "**4.In df, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApSZ6DF1tZ8i"
      },
      "source": [
        "# Input\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "# print(df.describe())\n",
        "# print(df['Min.Price'],df['Max.Price'])\n",
        "# Solution\n",
        "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
        "# print(df['Min.Price'].isna().sum(),df['Max.Price'].isna().sum())\n",
        "df[['Min.Price', 'Max.Price']] = d['Min.Price'],d['Max.Price']\n",
        "# print(df['Min.Price'].isna().sum(),df['Max.Price'].isna().sum())\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG7QW6u-tj9P"
      },
      "source": [
        "**5.Create a new column such that, each row contains the row number of nearest row-record by euclidean distance.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3okzaSYFtwR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0834a407-e9e8-4efe-cf2f-24568fa23304"
      },
      "source": [
        "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
        "import numpy as np\n",
        "nearest_rows = []\n",
        "nearest_distance = []\n",
        "# print(df)\n",
        "# iterate rows.\n",
        "for i, row in df.iterrows():\n",
        "    # print(row)\n",
        "    curr = row\n",
        "    rest = df.drop(i)\n",
        "    # print(curr)\n",
        "    e_dists = {}  # init dict to store euclidean dists for current row.\n",
        "    # iterate rest of rows for current row\n",
        "    for j, contestant in rest.iterrows():\n",
        "        # print(j)\n",
        "        # compute euclidean dist and update e_dists\n",
        "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
        "\n",
        "    # ky=list(e_dists.keys())\n",
        "    # val =list(e_dists.values())\n",
        "    # print(max(e_dists,key=e_dists.get))\n",
        "    # print(ky[val.index(max(val))])\n",
        "\n",
        "    # update nearest row to current row and the distance value\n",
        "    nearest_rows.append(max(e_dists,key=e_dists.get))\n",
        "    nearest_distance.append(max(e_dists.values()))\n",
        "   \n",
        "\n",
        "df['nearest_row'] = nearest_rows\n",
        "df['dist'] = nearest_distance\n",
        "print(df)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    p   q   r   s nearest_row   dist\n",
            "a  60  28  99  79           f  131.0\n",
            "b  41  67  81  52           j   91.0\n",
            "c   8  59   8  67           a  110.0\n",
            "d   7  23  32   4           a  114.0\n",
            "e  57  26  45  23           c   82.0\n",
            "f  20  85  12  11           a  131.0\n",
            "g  45  74  35  21           a   99.0\n",
            "h  57  60  50  33           a   74.0\n",
            "i  11  24  17  38           a  104.0\n",
            "j  65  77   3  14           a  126.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}